<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
    <ment="zbzheng" />
    <meta charset="utf-8">
    <meta http-equiv="content-type" content="text/html;charset=iso-8859-2" />
    <link rel="stylesheet" href="../css/mystyle.css" type="text/css" />
    <title>WS-DREAM</title>

    <script language="javascript" type="text/javascript">
    </script>
    <style type="text/css">
<!--
.STYLE1 {color: #000000}
.STYLE3 {color: #CC3300}
.STYLE4 {font-size: 1em}
.STYLE8 {
	color: #FFFFFF;
	font-size: 1.2em;
	font-weight: bold;
}
.STYLE9 {font-size: 1em; color: #000000; }
.STYLE10 {color: #FFFFFF}
        .style1
        {
            color: #000000;
            font-weight: bold;
        }
-->
    </style>
</head>


<body>
    <div class="content">
        <div class="subheader">
        <p>&nbsp;</p>
            <p class="STYLE1"><font size='2'>Part of the papers which use the WS-DREAM dataset are listed bellow: </font></p>
            <p>&nbsp;</p>
            <ol class="STYLE1">
                <li>
                    <div><a href="./papers/RegionKNN A Scalable Hybrid Collaborative Filtering Algorithm for Personalized Web Service Recommendation.pdf">RegionKNN: A Scalable Hybrid Collaborative Filtering Algorithm for Personalized Web Service Recommendation</a><br/>
                    We adopt the WSRec [5] dataset, which contains about 1.5 million web service invocation records of 100 web services from more than 20 countries. RTT records are collected by 150 computer nodes from Planet-Lab, which are distributed in more than 20 countries. We extract a subset of 300,000 RTT records, which ranges from 2 to 31407 milliseconds. 3000 users are generated, each of whom is associated with a RTT profile of all the 100 services.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/An Effective Web Service Recommendation Method based on Personalized Collaborative Filtering.pdf">An Effective Web Service Recommendation Method based on Personalized Collaborative Filtering</a><br/>
                    We adopt a dataset provided by ZiBin Zheng [17] for our experiments. The dataset contains 150 files, where each file includes 10,000 Web service invocations on 100 Web services by a service user. There are totally more than 1.5 millions Web service invocations. Each line in the file is a Web service invocation result, where the Table IV provides several samples of the results. In this table, the ClientIP denotes different users, WSID represents different service items. The other four items are QoS attributes.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Location-Aware Collaborative Filtering for QoS-Based Service Recommendation.pdf">Location-Aware Collaborative Filtering for QoS-Based Service Recommendation</a><br/>
                    In our experiments, we adopt a real-world Web service dataset: WSDream dataset 2<sup>5</sup> , which was published in references [12,13]. The dataset contains QoS records of service invocations on 5825 Web services from 339 service users, which are transformed into a user-service matrix. Each item of the user-service matrix is a pair of values: Round-Trip Time (RTT) and throughput (TP). Therefore the original user-service matrix can be decomposed into two simpler matrices: RTT matrix and TP matrix. We use either RTT matrix or TP matrix to compute user similarity and service similarity in the experiments.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Collaborative Web Service QoS Prediction with Location-Based Regularization.pdf">Collaborative Web Service QoS Prediction with Location-Based Regularization</a><br/>
                    We have conducted our experiments on a public real world Web service QoS dataset, which is collected by Zibin Zheng et.al. It contains 1,974,675 Web service response time records. These results are collected from 339 distributed service users on 5,825 Web services. Each user record contains geographical information. More details about this dataset can be found in [7].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/An Extended Matrix Factorization Approach for QoS Prediction in Service Selection.pdf">An Extended Matrix Factorization Approach for QoS Prediction in Service Selection</a><br/>
                    We have conducted our experiments on a public real world Web service QoS dataset, which is collected by Zibin Zheng et.al. It contains 1,974,675 Web service response time records. These results are collected from 339 distributed service users on 5,825 Web services. More details about this dataset can be found in [9].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Recommending Web Services via Combining Collaborative Filtering with Content-based Features.pdf">Recommending Web Services via Combining Collaborative Filtering with Content-based Features</a><br/>
                    Luckily, there is a recent effort made by Zheng et al. [5] in their WS-DREAM project6, which shares a large-scale real Web service dataset. WS-DREAM developed a Web crawling engine to crawl publicly available WSDL file addresses from the Internet. It also collected non- functional attributes (e.g., QoS) of these Web services, which are observed by 339 distributed computers located in 30 different countries, from Planet-Lab7. We use this dataset as our base dataset and perform the following pre-processing<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Hybrid Collaborative Filtering algorithm for bidirectional Web service recommendation.pdf">Hybrid Collaborative Filtering algorithm  for bidirectional Web service recommendation</a><br/>
                    Our experiments employ the real-world Web service QoS data set.1 The dataset includes 100 publicly available Web services hosted by more than 20 providers and 150 distributed computers from Planet-Lab [7,34]. The service consumers (distributed computer from Planet-Lab) observe and collect QoS attributes of Web services. By processing the open source files, we construct a 150 × 100 × 20 consumer-service-provider cube.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Web Service QoS Prediction based on Multi Agents.pdf">Web Service QoS Prediction based on Multi Agents</a><br/>
                    In this simulation we have used the WS-DREAM dataset represented by Zibin Zheng and Michael R. Lyu in [18] which is offers real world web service invocation data. The data given for web service response time (ms) was used in order to simulate our QoS prediction mechanism.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Decision Tree Learning from Incomplete QoS to Bootstrap Service Recommendation.pdf">Decision Tree Learning from Incomplete QoS to Bootstrap Service Recommendation</a><br/>
                    The experiments are conduced on a real world QoS dataset that consists of 1.5 million service invocation records. 150 computer nodes from the Planet-Lab<sup>2</sup>, which are located in over twenty countries, are leveraged to automatically invoke a hundred selected Web services. These services are distributed across more than twenty countries. Each computer node invokes each service for 100 times and the average Round-Trip Time (RTT) is used as the QoS dataset in our experiments.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Personalized Context-Aware QoS Prediction for Web Services Based on Collaborative Filtering.pdf">Personalized Context-Aware QoS Prediction for Web Services Based on Collaborative Filtering</a><br/>
                    In the experiment we use the dataset from the WSRec including a user-contribution mechanism for Web Service QoS information collection, which is implemented by java language and deployed to the real-world environment [5, 14]. This dataset includes 100 Web Services and 150 computer nodes (users) which are distributed in 22 countries. We obtain a 150×100 user-service item matrix from this database, where each entry in the matrix represents the QoS value (RTT).<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/QoS Driven Web Services Evolution.pdf">QoS Driven Web Services Evolution</a><br/>
                    In our experimental scenario we use dataset from the WSRec including a user-contribution mechanism for web service QoS information collection, which is implemented by java language and deployed to the real-world environment [8, 9]. This dataset includes 100 web services and 150 computer nodes (users) which are distributed in 22 countries. We obtain a 150×100 user-service item matrix from this database, where each entry in the matrix represents the QoS values (e.g., RTT, Failure-rate).<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Trust-Based Personalized Service Recommendation: A Network Perspective.pdf">Trust-Based Personalized Service Recommendation: A Network Perspective</a><br/>
                    In this study, we use a real world dataset from WS-DREAM1[39]. The characteristics of the dataset are described in Table 1. 100 users invoked 2 000 real world services from public sources on the Web. Each user invoked each service 30 times. The behaviors of services in each interaction, as well as the observed QoS performance (response time and throughput) were recorded.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/WSRank A Collaborative Ranking Approach for Web Service Selection.pdf">WSRank: A Collaborative Ranking Approach for Web Service Selection</a><br/>
                    We adopt the WSRec [7] dataset, which contains about 1.5 million web service invocation records of 100 web services from more than 20 countries. We extract a subset of 300,000 QoS records and 3000 users are generated, each of whom is associated with a QoS profile of all the 100 services. As for our QoS model, we take two QoS properties, RTT and throughput with equal weight as an example.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/QoS-aware service selection via collaborative QoS evaluation.pdf">QoS-aware service selection via collaborative QoS evaluation</a><br/>
                    We use the real-world QoS dataset created by WSRec [40]. In WSRec, a list of 21,197 publicly available Web services are obtained by crawling leading service provider websites, portal websites that publish publicly available Web services, and service search engines. The actual working services are less due to authentication restriction, permanent invocation failure, or extremely long processing duration. One hundred Web services are randomly selected from the working services.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Multi-user web service selection based on multi-QoS prediction.pdf">Multi-user web service selection based on multi-QoS prediction</a><br/>
                    To study the prediction performance on multi-QoS, we con- duct several experiments to show the prediction quality of our proposed approach on real-world Web service dataset (Zheng et al. 2010). This dataset includes QoS performance of 5,825 openly-accessible real-world Web services from 73 countries. The QoS values are observed by 339 distributed computers located in 30 countries from PlanetLab4. The detail can be describe as Table 1.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Personalized Location-Aware QoS Prediction for Web Services Using Probabilistic Matrix Factorization.pdf">Personalized Location-Aware QoS Prediction for Web Services Using Probabilistic Matrix Factorization</a><br/>
                    The dataset offered by Zheng et al. [18], which contains 339 users and 5825 Web services, is used to conduct our experiments. Geographical information and response time are gained from the file userlist.txt and rtmatrix.txt respectively.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Recommending Web Service Based on User Relationships and Preferences.pdf">Recommending Web Service Based on User Relationships and Preferences</a><br/>
                    We perform our experiment on two datasets. One is the Movielens dataset, the most commonly used dataset for movie recommendation [9], and the other is WSDream-QoSDataset provided by Zibin Zheng in the Chinese University of Hong Kong [6].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Personalized QoS Prediction for Web Services using Latent Factor Models.pdf">Personalized QoS Prediction for Web Services using Latent Factor Models</a><br/>
                    To evaluate the performance of our approach, we choose the real-world Web service QoS dataset offered by Zheng et al [23]. The detailed statistics of the Web services QoS dataset is summarized in Table I. Our experiments concentrate on the response time QoS characteristic.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Kind Of Web Service Recommendation Method Based On Improved Hybrid Collaborative Filtering.pdf">A Kind Of Web Service Recommendation Method Based On Improved Hybrid Collaborative Filtering</a><br/>
                    We adopt a dataset provided by ZiBin Zheng [12] for our experiments. The dataset contains 150 files, where each file includes 10,000 Web service invocations on 100 Web services by a user. Each line in the file is a Web service invocation result and there are totally more than 1.5 millions Web service invocations. That is to say what we used is 150 × 100 user- service matrix.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Colbar A collaborative location-based regularization framework for QoS prediction.pdf">Colbar: A collaborative location-based regularization framework for QoS prediction</a><br/>
                    We have conducted our experiments on a public real world Web service QoS dataset, which is collected by Zibin Zheng et.al. It contains 1,974,675 Web service response time and throughput records. The range of response time property is 0–20 s while the range of throughput is 0–1000 kbps. These results are collected from 339 distributed service users on 5,825 Web services. Also each user records personal longitude and latitude information. More details on this dataset can be found in [22].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/基于协同过滤的个性化 Web 服务选择方法.pdf">基于协同过滤的个性化 Web 服务选择方法</a><br/>
                    在该实验中使用大规模真实环境下收集到的QoS数据集（WS-DREAM）［3，13］，该数据集收集了分布在全球20多个国家的150个服务用户调用100个服务的150万条调用纪录。从该数据集中可以提取150＊100的用户－服务矩阵，矩阵中的每项代表失效率和响应时间。<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/面向个性化服务推荐的QoS动态预测模型.pdf">面向个性化服务推荐的QoS动态预测模型</a><br/>
                    WS-Dream数据集是一个公开的用于Web服务推荐研究的数据集合,包含不同用户在不同地点、不同时间段使用Web服务的服务质量记录(响应时间、吞吐量),目前分为4个子数据集.笔者将采用含有时间维 度信息的子数据集[81进行分析,其中包含142个用户在64个时段对4 532个服务的响应时间和吞吐量记录. 该数据集为服务质量动态预测模型的研究提供了有效的数据支撑.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Time-Aware Collaborative Filtering for QoS-Based Service Recommendation.pdf">Time-Aware Collaborative Filtering for QoS-Based Service Recommendation</a><br/>
                    To evaluate our proposed time-aware QoS prediction approach in the real-world, this paper adopt a real-world Web service Dataset WSDream dataset 3 2, which was published in references [3].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Efficient web service QoS prediction using local neighborhood matrix factorization.pdf">Efficient web service QoS prediction using local neighborhood matrix factorization</a><br/>
                    We have conducted our experiments on a public real world web service QoS dataset, which is collected by Zheng et al. (2011). It contains 1,974,675 web service response time (0–20 s), collected from 339 distributed service users on 5825 web services world- wide. Also the profile of each user includes personal latitude and longitude information.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Web service QoS prediction approach based on time- and location-aware collaborative filtering.pdf">A Web service QoS prediction approach based on time- and location-aware collaborative filtering</a><br/>
                    To evaluate our approach in the real world, this paper adopts a real-world Web service data set WSDream data set 3,6 which was published in Ref. [5]. In order to evaluate our approach, we get the users’ IP and services’ URL from Zheng who is the second author of the paper [5]. And the users’ IP and Web Services’ URL of WSDream data set 3 can be found in our Web site.7<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/CloudRec a framework for personalized service Recommendation in the Cloud.pdf">CloudRec: a framework for personalized service Recommendation in the Cloud</a><br/>
                    We conduct a set of experiments to evaluate the effectiveness of the proposed QoS assessment model and the iterative algorithm. The experiments are conducted on two real-world QoS datasets obtained from [43,44,46]:<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/QoSDIST A QoS Probability Distribution Estimation Tool for Web Service Compositions.pdf">QoSDIST: A QoS Probability Distribution Estimation Tool for Web Service Compositions</a><br/>
                    In this paper, the QoS samples of the two web services Random Image and Dilbert are from WS-DREAM dataset [15].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/基于可信联盟的服务推荐方法.pdf">基于可信联盟的服务推荐方法</a><br/>
                    文献[23]给出了一个真实的Web服务运行数据集.该数据集来自20多个国家、存储于Planet-Lab实验室的150台分布式计算机中.本文选取该数据集作为仿真数据源,对每个用户而言,其对任意10个服务进行10次调用的记录将形成一个用户日志文件.若选定其中150个用户日志文件,因此会生成150万次调用记录.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Feedback-corrected Collaborative Filtering for Personalized Real-world Service Recommendation.pdf">A Feedback-corrected Collaborative Filtering for Personalized Real-world Service Recommendation</a><br/>
                    In order to has sufficient data to evaluate our approach, we use the web-service QoS set [24] which contains 1873838 real RTT (route trip time) records on 5825 real web-services from 339 distributed service users. To our knowledge, this is the largest dataset in the domain of service-computing. In order to collect the data, Zheng et al. monitor 5825 web-services using 339 distributed planet-lab computers.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Time-Aware and Data Sparsity Tolerant Approach for Web Service Recommendation.pdf">A Time-Aware and Data Sparsity Tolerant Approach for Web Service Recommendation</a><br/>
                    We adopt a freely available dataset provided by Zhang et al. [22] for experiments. They employed 142 distributed computers from Planet-Lab1 to evaluate the response time of 4532 Web services during 64 continuous time intervals, with each time interval lasting for 15 minutes. So, the dataset contains 64 142×4532 user-service matrices for response time.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Quality of Web Service Prediction by Collective Matrix Factorization.pdf">Quality of Web Service Prediction by Collective Matrix Factorization</a><br/>
                    We download the user-service invocation records (WSDream-QoSDataset24) as the data set for our experimental study. We randomly choose 2,502 services and classify these service in to 8 categories by analyzing the wsdl files. Table I lists the number of services in these categories.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/The QoS Prediction of Web Service with Location Information Ensemble.pdf">The QoS Prediction of Web Service with Location Information Ensemble</a><br/>
                    We adopt a real-world web service QoS performance dataset for the experiment [8]. The dataset contains about 1.5 million web service invocation records of 100 web services from more than 20 countries. The QoS values include the response-time and throughput. We randomly choose 5, 10 and 20 percent QoS values of the initial training matrix to generate sparse matrices for experiments.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Predicting Web Service QoS via Combining Matrix Factorization with Network Location.pdf">Predicting Web Service QoS via Combining Matrix Factorization with Network Location</a><br/>
                    In our experiments, we adapt a public real world Web service QoS dataset, which is collected by Zibin Zheng, et al., It contains QoS records of 1,974,675 web service invocations executed by 339 distributed service users on 5825 web services, which are transformed into two user-service matrices. The values of the two user-service matrices are response time and throughput respectively. More details about this dataset can be found in [11].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/On Bootstrapping Web Service Recommendation.pdf">On Bootstrapping Web Service Recommendation</a><br/>
                    We carry out a set of experiments to evaluate the effectiveness of the proposed frame- work for boostrapping service recommendation. The experiments are conduced on a real-world QoS dataset that consists of 1.5 million service invocation records. 150 computer nodes from the Planet-Lab,3 which are located in over twenty countries, are leveraged to automatically invoke a hundred selected Web services. These services are distributed across more than twenty countries. Each computer node invokes each service for 100 times and the average Round-Trip Time (RTT) is used as the QoS dataset in our experiments.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Predicting Web Service QoS via Matrix-factorization-based Collaborative Filtering under Non-negativity Constraint.pdf">Predicting Web Service QoS via Matrix-factorization-based Collaborative Filtering under Non-negativity Constraint</a><br/>
                    We conduct our experiments on the WS-Dream-Dataset [10, 20]. This dataset records the response time and throughput during the invocations of 5825 real-world Web-services by 339 users. Both the response time and throughput data are employed during our experiment. The details of these two parts are summarized in Table I.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Diversifying Web Service Recommendation Results via Exploring Service Usage History.pdf">Diversifying Web Service Recommendation Results via Exploring Service Usage History</a><br/>
                    To obtain solid experimental results, it is ideal to use a real world Web service dataset. Zheng et al. [29] pub- lished a large-scale real world Web service dataset ac- quired in their WS-DREAM project1. WS-DREAM is a Web service crawling engine that collects publicly availa- ble WSDL file addresses from the Internet. It also col- lected QoS information of these Web services by using 339 distributed computers to monitor the Web services. This dataset has been widely used for performance evalu- ation by previous work on Web service recommendation.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Time Aware and Data Sparsity Tolerant Web Service Recommendation Based on Improved Collaborative Filtering.pdf">Time Aware and Data Sparsity Tolerant Web Service Recommendation Based on Improved Collaborative Filtering</a><br/>
                    We use a freely available dataset provided by Zhang et al. [33] for experiments. They employed 142 distributed computers from Planet-Lab1 to evaluate the response time and throughput of 4532 Web services during 64 continuous time intervals, with each time interval lasting for 15 minutes. Accordingly, the dataset contains 64 matrices for response time and 64 matrices for throughput, and each matrix has 142 rows and 4532 columns.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A data-centric and machine based approach towards fixing the cold start problem in web service recommendation.pdf">A data-centric and machine based approach towards fixing the cold start problem in web service recommendation</a><br/>
                    For the purpose of experimentation, we use the dataset provided by [11] consisting of 150 real world web services invoked by 100 users. The data collection is done from the distributednodesaroundtheworldusingPlanetLab.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/An Effective Automatic Update Approach for Web Service Recommender Systems Based on Feedforward-Feedback Control Theory.pdf">An Effective Automatic Update Approach for Web Service Recommender Systems Based on Feedforward-Feedback Control Theory</a><br/>
                    The publicly available dataset used in our experiments is collected by Zhang [25]. 142 distributed computers from Planet-Lab1 were employed to monitor the response time of 4532 Web services in 64 time intervals. So the dataset contains 64 145×4532 user-service matrices for response time.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Hybrid Approach to Web Service Recommendation Based on QoS-Aware Rating and Ranking.pdf">A Hybrid Approach to Web Service Recommendation Based on QoS-Aware Rating and Ranking</a><br/>
                    In this paper, we used a public data set of real-world Web services introduced in (Zheng, Zhang et al. 2010), which contains over one and a half millions QoS records from 339 users and 5825 Web services distributed all over the world. The density of the user-service matrix in this data set used for evaluation is 94.9%. For more details of this data set, please refer to the literature (Zheng, Zhang et al. 2010; Zhang, Zheng et al. 2011b).<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Novel QoS-Based Approach for Web Service Recommendation and Visualization.pdf">A Novel QoS-Based Approach for Web Service Recommendation and Visualization</a><br/>
                    Web service QoS dataset was evaluated in the context of four different data sets collected from following web site: http://www.wsdream.net. Dataset contain some information about the web service invocations records.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Bayesian Personalized Ranking for Optimized Personalized QoS ranking.pdf">Bayesian Personalized Ranking for Optimized Personalized QoS ranking</a><br/>
                    Second dataset contains 339 numbers of service users and 5825 web services. These values are represented in matrix such as 339x5825 user item matrix.[1][10]<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Unified Framework of QoS-based Web Service Recommendation with Neighborhood-Extended Matrix Factorization.pdf">A Unified Framework of QoS-based Web Service Recommendation with Neighborhood-Extended Matrix Factorization</a><br/>
                    In our experiments, the real-world dataset provided by Zheng et al. [20] is used, which contains 339 users and 5825 Web services all around the world.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Generating Highly Accurate Predictions for Missing QoS Data via Aggregating Nonnegative Latent Factor Models.pdf">Generating Highly Accurate Predictions for Missing QoS Data via Aggregating Nonnegative Latent Factor Models</a><br/>
                    Data Set: The experiments are conducted on two data sets collected by the WS-Dream system [3], [11]. These two data sets consist of the response time and throughput of the invocations on 5825 real-world WSs by 339 users, respec- tively. Their details are summarized in Table I.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Towards Improving Recommender System A Social Trust-Aware Approach.pdf">Towards Improving Recommender System: A Social Trust-Aware Approach</a><br/>
                    To evaluate STRESS’s performance, we conducted a series of large-scale simulation experiments based on three real-world dataset from WS-DREAM [30] that capture interactions between users and WSs. The first dataset [31] contains 150 files, where each file includes 10,000 WS invocations on 100 WSs by a service user. Table 1 provides some samples of the results.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Personalized Web Services Recommendation Based on Hybrid Collaborative Filtering Algorithm.pdf">Personalized Web Services Recommendation Based on Hybrid Collaborative Filtering Algorithm</a><br/>
                    实验使用 Zheng 等人提供的数据集 WS-DREAM (http://www.wsdream.net)中的数据。其中从 24 个国 家中选取 150 个 Web 服务用户和 100 个 Web 服务,构 成具有 150 万条调用记录的服务质量数据集。实验 中只针对响应时间属性比较各个方法的性能,将实 际获取的响应时间用 min-max 标准化方法进行归一 化处理。随机产生每个用户对响应时间的期望值, 根据响应时间和期望值的差值情况生成用户评分, Web 服务数据样例如表 2 所示。聚类数量设置为 50。<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/基于QoS感知的Web服务推荐算法.pdf">基于QoS感知的Web服务推荐算法</a><br/>
                    实验使用WSRec数据集[7]，该数据集使用Planet—Lab上分布在20多个国家的150个计算机节点对100个可公共访问的Web服务进行调用，每个节点调用记录包含100个文档(profile)，每个文档包含对100个Web服务的一次调用结果，WSRec数据集总共包含150万次调用记录。我们从每个节点中随机抽取10个文档，共获得1500个用户。<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/基于QoS反向预测的服务推荐.pdf">基于QoS反向预测的服务推荐</a><br/>
                    为了量化分析RST算法对预测效果的提升,本文基于一个真实的公共数据集WS-DREAM[l]引进行实验.数据集包含来自不同地区的150名用户,对100个不同Web服务的1,542,884条完整调用记录,每条记录由:IP、WSID(Web服务ID)、RTT(round—trip time)、数据包大小、帅响应码以及HTTP响应信息,共6个参数组成.实验提取出每条记录的前三个参数,构建RST模型,并在此基础上评估分析RST算法的准确性. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Game Theory-based Approach to Service Rating.pdf">A Game Theory-based Approach to Service Rating</a><br/>
                    As there are no real-world data available for evaluating a rating system in the presence of manipulators, simulations were used to compare the rating prediction accuracy of the proposed scheme (GTS) with the schemes by Zheng et al.[15] (WSRec), Malik et al. [7] (RATEWeb), and Zhang et al. [14] (Personalised).<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Highly Accurate Prediction Algorithm for Unknown Web Service QoS Values.pdf">A Highly Accurate Prediction Algorithm for Unknown Web Service QoS Values</a><br/>
                    We adopted WSDream to validate our prediction algorithm. We implemented the experiments employing JDK 7.0 and eclipse 4.3 on Windows Server 2008 R2 Enterprises with Inter Xeon E5-2670 eight-core 2.60 GHz CPU and 32G RAM. Our experiments mainly consists of two parts: 1) Section 3.3 compares our algorithm with other 7 well known prediction methods based on the throughput as well as response time dataset; 2) Section 3.4 and 3.5 study the optimal parameters user_topK and item_topK of our algorithm.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A location-aware hybrid web service QoS prediction algorithm.pdf">A location-aware hybrid web service QoS prediction algorithm</a><br/>
                    In this section, we verify the performance of HUWAA through experiments. The dataset, collected by Zheng et al. [12], contains 1 974 675 recorded response times of users invoking online services. More specifically, the dataset contains the response times and throughput records of 339 users and 5 825 Web services. For our experiments, we randomly sampled 150 users and Web services.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Robust Service Recommondation Scheme.pdf">A Robust Service Recommondation Scheme</a><br/>
                    Some experiments were carried out to evaluate the prediction accuracy and the robustness of the proposed scheme. In the experiments, all the attributes of a service are given equal weight in formula (1). In L is set to 3. The first experiment compares the prediction accuracy of the proposed scheme with the scheme by Zheng et al.[25] which is one of the best service recommendation schemes. The comparison used the data set collected by Zheng [24] and Zhang [23] (http://www.wsdream.net).<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Cloud Service Recommendation based on Trust Measurement Using Ternary Interval Numbers.pdf">Cloud Service Recommendation based on Trust Measurement Using Ternary Interval Numbers</a><br/>
                    We used the WS-DREAM datasets [15], and supplemented some real data about user feature, including AS number, city, network description or area, and so on. And the detailed raw data used by our experiments are provided online [16]. Then a three-level location code, consisting of country, city and area, can be generated. The datasets provides response time matrix of service invocations. Comparing the response time provided by consumers with user expectation value, the trust degree of QoS is calculated as follows.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Collaborative QoS Prediction via Feedback-based Trust Model.pdf">Collaborative QoS Prediction via Feedback-based Trust Model</a><br/>
                    We have conducted our experiments using a public real-world Web service QoS dataset, which is collected by Zibin Zheng et.al [8]. It contains the records of 1,974,675 Web service invocations executed by 339 distributed service users on 5825 Web services. The record of each invocation contains 2 parameters: Response Time and Throughput. More details about this dataset can be found in [6]. In this paper, we randomly extract 150 users, 100 Web services and use the invocation records between them as the experimental data.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Collaborative QoS Prediction via Matrix Factorization and Topic Model.pdf">Collaborative QoS Prediction via Matrix Factorization and Topic Model</a><br/>
                    Zibin’s dataset [19],[20] is popularly used in a number of papers [14],[17], this is a real-world dataset which only consists of two types of QoS but not WSDL files. In order to discover the topic information of Web services, we crawl the corresponding WSDL files whose URLs (Uniform Resource Locator) have been given in Zibin’s dataset from Internet. In this paper, our dataset primarily consists of the users- Web services responding time QoS matrix and WSDL files of corresponding services. There are 339 users and 2344 Web services in our dataset.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Collaborative Web Service QoS Prediction on Unbalanced Data Distribution.pdf">Collaborative Web Service QoS Prediction on Unbalanced Data Distribution</a><br/>
                    We adopt a real-world Web service dataset: WSDream dataset 2, which was published in references [13]. The dataset contains QoS records of service invocations on 5825 Web services from 339 service users, which are transformed into a user-service matrix. Each item of the user-service matrix is a pair of values: response-time and throughput.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Combining QoS prediction and customer satisfaction estimation to solve cloud service trustworthiness evaluation problems.pdf">Combining QoS prediction and customer satisfaction estimation to solve cloud service trustworthiness evaluation problems</a><br/>
                    To ensure the typicality and objectivity of QoS prediction, an open QoS research dataset [37] will be employed to predict the assessment data on Performance and Availability. These QoS data (response-time and throughput) were collected from 339 users on 5825 web services in a real-world environment. Since it is impractical to discover and distinguish all functionally-equivalent cloud services at the selection time, we randomly select 100 web services’ QoS reports for our experiment.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Context-aware Prediction of QoS and QoE Properties for Web Services.pdf">Context-aware Prediction of QoS and QoE Properties for Web Services</a><br/>
                    To this end, the second dataset of [10] is used to evaluate the methods with regard to the output dimensions response time and throughput. This dataset comprises 5825 real-world Web Services and 339 users from various parts of the world and the response times and throughputs for each pair of users and services. Furthermore, the countries of the service providers and the geographic coordinates of the users are provided and thus the approximate distances between them.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Decision Support for Personalized Cloud Service Selection through Multi-Attribute Trustworthiness Evaluation.pdf">Decision Support for Personalized Cloud Service Selection through Multi-Attribute Trustworthiness Evaluation</a><br/>
                    We employ an open QoS research dataset [43] to simulate the historical records of Performance and Availability in cloud service market. The QoS values for response-time and throughput were collected from 339 users over 5825 web services in a real-world environment.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Fusion of Pearson Similarity and Slope One Methods for QoS Prediction for Web Services.pdf">Fusion of Pearson Similarity and Slope One Methods for QoS Prediction for Web Services</a><br/>
                    In order to validate the effectiveness of our proposed algorithm for QoS prediction, some experiments are employed on a public published data set, which is collected by Zheng et al. [5] and has been widely adopted in the current researches [7,15]. The original data set contains 5825 service invocation records from 339 users, and QoS attributes include response time (RT) and throughput (TP).<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Multimedia services quality prediction based on the association mining between context and QoS properties.pdf">Multimedia services quality prediction based on the association mining between context and QoS properties</a><br/>
                    We have conducted our experiments using a public real-world Web-service QoS dataset, which is collected in [31]. It contains the records of 1,974,675 Webservice invocations executed by 339 distributed service users on 5825 Webservices. Each user is described by UserID, IP address of user, country, longitude, latitude. Each service is described by WSID, WSDL address, provider name, country name.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Online Optimization of Collaborative Web Service QoS Prediction Based on Approximate Dynamic Programming.pdf">Online Optimization of Collaborative Web Service QoS Prediction Based on Approximate Dynamic Programming</a><br/>
                    To test the performance of our approach in real-world, we use a common data set collected from 339 service users on 5, 825 web services [9]. This experiment focuses on the investigation for the response time of different web services and service users. Response time is one of the representative QoS values, which is defined as the time duration between sending a request and receiving a corresponding response for a service user.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Performance Evaluation of Web-Services Classification.pdf">Performance Evaluation of Web-Services Classification</a><br/>
                    A mechanism for past Web service QoS information collection using different service users was proposed by Zheng et al.12. Based on collected QoS data, a collaborative filtering approach predicted Web service QoS values. In the end, a prototype called WSRec was implemented through Java language and deployed in the Internet to conduct real-world experiments.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/QoS prediction algorithm used in location-aware hybrid Web service.pdf">QoS prediction algorithm used in location-aware hybrid Web service</a><br/>
                    In this section, the authors verify the performance of HUWAA through experiments. The dataset, collected by Zheng et al. [12], contains 1 974 675 recorded response times of users invoking online services. Especially, the dataset contains the response times and throughput records of 339 users and 5 825 Web services. For the experiments here, 150 users and Web services were randomly sampled.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/QoS Prediction forWeb Services Based on Similarity-Aware Slope One Collaborative Filtering.pdf">QoS Prediction forWeb Services Based on Similarity-Aware Slope One Collaborative Filtering</a><br/>
                    In order to validate the effectiveness of our proposed algorithm for QoS prediction, some experiments are employed on a public published data set1, which is collected by Zheng et al. [5] and has been widely adopted in the current researches [7, 15]. The original data set contains 5825 service invocation records from 339 users, and QoS attributes include response time (RT) and throughput (TP).<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Search-based QoS ranking prediction for web services in cloud environments.pdf">Search-based QoS ranking prediction for web services in cloud environments</a><br/>
                    To validate the effectiveness of our search-based QoS ranking algorithm, we performed experiments on some publicly available Web services QoS data1 which had been collected by Zheng et al. [18,10]. The data set includes 500 eal-world Web services with 300 distributed computers (users) on the Planet-Lab2 platform, and so the Web QoS values were gathered by monitoring service invocation from the distributed computers (users).<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/SPW Scheduling and Positioning of Web- Services.pdf">SPW: Scheduling and Positioning of Web- Services</a><br/>
                    depicts the compiled priority scheduled data. This paper, collected data used in WSP approach [11] a QoS dataset for experiment, comprising the response times between 200 users (PlanetLab nodes) and 1,597 Web services, together with the network distances between the 200 distributed nodes, for our SPW approach. And response time is calculated using QOS based algorithm[11].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Time Aware and Data Sparsity Tolerant Web Service Recommendation Based on Improved Collaborative Filtering.pdf">Time Aware and Data Sparsity Tolerant Web Service Recommendation Based on Improved Collaborative Filtering</a><br/>
                    We use a freely available dataset provided by Zhang et al. [33] for experiments. They employed 142 distributed computers from Planet-Lab1 to evaluate the response time and throughput of 4532 Web services during 64 continuous time intervals, with each time interval lasting for 15 minutes. Accordingly, the dataset contains 64 matrices for response time and 64 matrices for throughput, and each matrix has 142 rows and 4532 columns.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Topic Model based Collaborative QoS Prediction.pdf">Topic Model based Collaborative QoS Prediction</a><br/>
                    Zibin’s dataset [22],[23] is popularly used in a number of papers [15],[20], this is a real-world dataset which only consists of two types of QoS but not WSDL files. In order to discover the topic information of Web services, we crawl the corresponding WSDL files whose URLs (Uniform Resource Locator) have been given in Zibin’s dataset from Internet. In this paper, our datasets primarily consist of the users-Web services responding time QoS matrix and WSDL files of corresponding services.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Towards QoS Prediction for Web Services based on Adjusted Euclidean Distances.pdf">Towards QoS Prediction for Web Services based on Adjusted Euclidean Distances</a><br/>
                    We have conducted our experiments using a public realworldWeb service QoS dataset, which is collected by Zibin Zheng et.al [9]. It contains the records of 1, 974, 675 Web service invocations executed by 339 distributed service users on 5825 Web services. The record of each invocation contains 2 parameters: Response Time and Throughput. More details about this dataset can be found in [6]. In this paper, we randomly extract 150 users, 100 Web services and use the invocation records between them as the experimental data.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Unified Collaborative and Content-Based Web Service Recommendation.pdf">Unified Collaborative and Content-Based Web Service Recommendation</a><br/>
                    To perform reliable experiments, it is ideal to use large-scale real world web services. Unfortunately, collecting and preparing such data is extremely time-consuming. Fortunately, Zheng et al. [8] shared a large-scale real world web services dataset collected in their WS-DREAM project. WS-DREAM is a web crawling engine that crawled publicly available WSDL file addresses from the Internet.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Web Service Composition Optimization Based on Improved Artificial Bee Colony Algorithm.pdf">Web Service Composition Optimization Based on Improved Artificial Bee Colony Algorithm</a><br/>
                    In Web service QoS modeling research, Zhang et el. [1] presents a novel hybrid data type (including real numbers, interval numbers, triangular fuzzy numbers and intuitionistic fuzzy numbers) QoS model, and presented a dynamic composition algorithm based on TOPSIS (DWSCA_TOPSIS) is to evaluate multi-period hybrid QoS data. An intuitionistic fuzzy set-based QoS model was presented in Ref. [6]. A QoS model based on random numbers was resented in Ref. [8].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Web Service QoS Prediction under Sparse Data via Local Link Prediction.pdf">Web Service QoS Prediction under Sparse Data via Local Link Prediction</a><br/>
                    The dataset contains response time and throughput records of 339 users and 5825 Web services. And we randomly sample the users-Web services matrix for constructing the sparse data. We just use the spare data for predicting the response time.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Web Service Recommendation using Optimized Iterative Collaborative Filtering.pdf">Web Service Recommendation using Optimized Iterative Collaborative Filtering</a><br/>
                    In our experiments, a series of programs implemented with Matlab are running on a PC with Intel Xeon X7460 CPU and 64G RAM. Additionally, the data set we used in this paper is from WS-DREAM[18,22].19 Two features of the QoS value collected in the data set are response-time and throughput, both of which contain a user-item matrix(339*5825). To evaluate the prediction accuracy and performance of different models, 10 user-item matrices(150*200) without missing value are selected from the original data set to serve as the real world QoS data.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Investigating QoS of Real-World Web Services.pdf">Investigating QoS of Real-World Web Services</a><br/>
                    To attack this critical challenge, we make a great effort to conduct three large-scale distributed evaluations on real-world web services, collect comprehensive web service QoS data sets, and publicly release these reusable data sets for future research. First, 21,358 web service addresses are obtained by crawling web service information from the Internet. Then three web service evaluations are conducted. In the first evaluation, failure probability of 100 web services is assessed by 150 distributed service users. In the second evaluation, response time and throughput of 5,825 web services are evaluated by 339 distributed service users.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Framework for Similarity Search of Web Services.pdf">A Framework for Similarity Search of Web Services</a><br/>
                    The experiments were conducted over four datasets which were synthetically generated from the two publicly accessible WS data colletions4,5 The WS data in these collections are gathered from real world service sites.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Framework for Automated Service Negotiation.pdf">A Framework for Automated Service Negotiation</a><br/>
                    WSDream-QoSDataset [46] is used, which contains more than 150 Web services distributed in computer nodes located all over the world (i.e., distributed in 22 different countries). Planet-Lab is employed for monitoring the Web services. We take the published services and their corresponding QoS values and write our own wrappers that incorporate the NegFs negotiation component.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Binary PSO for Web Service Location-Allocation.pdf">Binary PSO for Web Service Location-Allocation</a><br/>
                    The datasets used for the experiments were generated from the WS-DREAM dataset [27]. The WS-DREAM dataset is a collection of historical data from 339 users and 5824 web services located in different locations. It records several non-functional attributes about the web services, including response time, IX throughput, availability, etc.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Web Service Discovery Method Based on Data Segmentation and WordNet.pdf">A Web Service Discovery Method Based on Data Segmentation and WordNet</a><br/>
                    Data used in this paper are from Dr. Yilei Zhang’s research results [13], including 3,738 WSDL files [14]. We use the JAVA language to extract Web service features in addition to using WSDL4J and Princeton WordNet<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Automated Negotiation Using Semantic Rules.pdf">Automated Negotiation Using Semantic Rules</a><br/>
                    WSDream-QoSDataset [28] is used, which contains more than 150 Web services distributed in computer nodes located all over the world (i.e., distributed in 22 different countries). Planet-Lab is employed for monitoring the Web services. We take the published services and their corresponding QoS values and write our own wrappers that incorporate the NegF's negotiation component.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Reducing search space for Web Service ranking using semantic logs and Semantic FP-Tree based association rule mining.pdf">Reducing search space for Web Service ranking using semantic logs and Semantic FP-Tree based association rule mining</a><br/>
                    However, such datasets are not publically available. We used and adapted a dataset from [22] and www.webservicelist.com which provides different parameters including functional and non-functional properties of Web Services. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Exploring QoS of Genuine Web Administrations.pdf">Exploring QoS of Genuine Web Administrations</a><br/>
                    In the first assessment, disappointment likelihood of 100 web administrations is surveyed by 150 appropriated administration clients. In the second assessment, reaction time and throughput of 5,825 web administrations are assessed by 339 appropriated administration clients. Also in the third assessment, QoS changing of 4,532 web administrations with time is mulled over by directing 30,287,611 web administration summons by 142 clients in 64 time openings with a period interim of 15 minutes. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Multidimensional Analysis of Heterogeneous Relationships in Internet of Things.pdf">Multidimensional Analysis of Heterogeneous Relationships in Internet of Things</a><br/>
                    However, Zheng et al.[156] shared a large-scale real world data in their WS-DREAM project. WS-DREAM is a crawling engine that crawled publicly available WSDL life addresses from the Internet. It also collected non-functional attributes (e.g. QoS) of these services, which are observed by 339 distributed computers located in 30 different countries, from Planet-Lab4. In our experiments, we used this dataset as our base dataset and performed some pre-processing activities.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/AN ADAPTIVE SYSTEM FOR WEB SERVICES THROUGHPUT PREDICTION.pdf">AN ADAPTIVE SYSTEM FOR WEB SERVICES THROUGHPUT PREDICTION</a><br/>
                    To train the adaptive model I use the Web service QoS dataset built by [3] They collected a 339 * 5825 user-item matrix for throughput, where an entry Ra,i in the matrix is the throughput of Web service i observed by the service user a.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Comparative Study on Machine Learning Techniques in Predicting the QoS-values for Web-Services Recommendations.pdf">Comparative Study on Machine Learning Techniques in Predicting the QoS-values for Web-Services Recommendations</a><br/>
                    So, we have taken the web services related dataset which was created by Zheng et al. [6]. The details about the dataset are given in table-I. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Novel Optimal and Scalable Nonfunctional Service Matchmaking Techniques.pdf">Novel Optimal and Scalable Nonfunctional Service Matchmaking Techniques</a><br/>
                    During the experiments, the experimental framework relies on generating the NFSSs either randomly or based on real measurements executed on real web services. For generating realistic NFSSs, the framework relies on the WS- Dream’s third QoS dataset [20] which was produced by measuring the performance of 4500 web services when invoked by 142 service users, distributed around the globe, in 64 time intervals. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Evaluation Method for Web Service with Large Numbers of Historical Records.pdf">A Evaluation Method for Web Service with Large Numbers of Historical Records</a><br/>
                    The employed experiment data is from web service QoS dataset WS-DREAM [9] published by Dr. Zibin Zheng in 2011. WS-DREAM consists of 4532 web services from public sources on the web, and 142 distributed computers from Planet-Lab are employed for evaluating the QoS performance of web services in 64 time intervals.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/User-credibility Based Service Reputation Management for Service Selection.pdf">User-credibility Based Service Reputation Management for Service Selection</a><br/>
                    To evaluate the performance of our user-credibility based service reputation management model, several experiments are conducted with WS-DREAM dataset provided by Zhang Y, Zheng Z and Lyu M R [16]. The dataset is stringency and authority, and includes 4,532 actual web services and QoS data monitored by 142 users in 64 time slots. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Monitoring Resources Allocation for Service Composition under Different Monitoring Mechanisms.pdf">Monitoring Resources Allocation for Service Composition under Different Monitoring Mechanisms</a><br/>
                    The value of mean response time is randomly chosen from two groups of experiment data collected from real services in the network: (1) the QWS Dataset [18-20]; (2) dataset collected by WS-DREAM [21,22] while the mean failure rate and repair rate of services is chosen from:(3) the sample data collected from the real-world services through Membrane, an open source web service registry and monitoring tool [23]. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/HS-SLA A Hierarchical Self-Healing SLA Model for Cloud Computing.pdf">HS-SLA: A Hierarchical Self-Healing SLA Model for Cloud Computing</a><br/>
                    This study used the throughput and respond time dataset collected from Zheng [47, 48] which its validity is confirmed in his study [48, 49]. This dataset includes the throughput and respond time of 5825 services which they are invoked by 339 users. Therefore, 339 throughputs and respond times are collected for each service. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Hierarchical Self-Healing SLA for Cloud Computing.pdf">A Hierarchical Self-Healing SLA for Cloud Computing</a><br/>
                    This study used the throughput and respond time dataset collected from Zheng [34, 35] which its validity is confirmed in his study [17, 35-37]. This dataset includes the throughput and respond time of 5825 services which they are invoked by 339 users. Therefore, 339 throughputs and respond times are collected for each service. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Hybrid Genetic Algorithm for Optimal Service Redundancy Configuration in Service Composition.pdf">Hybrid Genetic Algorithm for Optimal Service Redundancy Configuration in Service Composition</a><br/>
                    To evaluate MSHGA, we have simulated 10 groups of reliability, performance and cost data for 12 services in it. These data are randomly chosen from two datasets: (1) the QWS Dataset [23] and (2) dataset collected by WS-DREAM [16]. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Ranking Web Services with Limited and Noisy Information.pdf">Ranking Web Services with Limited and Noisy Information</a><br/>
                    In this paper, we adopt WSDream dataset, which includes response time and throughput QoS values of a number of web services in reality [24], [25]. The datasets are collected by executions of nearly 2 million real-world web service invocations from 339 service users in 30 different countries. 5,825 real-world web services from 73 countries are evaluated, and more than 3.9 million pieces of data are recorded. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Location-based Hierarchical Matrix Factorization for Web Service Recommendation.pdf">Location-based Hierarchical Matrix Factorization for Web Service Recommendation</a><br/>
                    Extensive experiments are conducted on a real world Web service QoS dataset with 339 users and 5825 services. Experimental results prove that our method is better than other state-of-the-art methods.  <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Location Aware Quality of Service (QoS) Based Recommendation System for Web Services.pdf">A Location Aware Quality of Service (QoS) Based Recommendation System for Web Services</a><br/>
                    A data set is a collection of data, usually presented as in table 5.2. In this project the data is taken from the dataset provided by WS-DREAM site. The dataset contains Real-World QoS evaluation results from 339 users on 5825 Web Services. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/QoS evaluation for web service recommendation.pdf">QoS evaluation for web service recommendation</a><br/>
                    We selected the WSDream dataset to validate TBQP. WSDream1 [9] is a traditional real Web service QoS dataset that has been widely studied. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Combination Approach to QoS Prediction of Web Services.pdf">A Combination Approach to QoS Prediction of Web Services</a><br/>
                    We have conducted our experiments using a public real-world Web service QoS data- set, which is collected by Zibin Zheng et.al [2]. It contains the records of 1,974,675 Web service invocations executed by 339 distributed service users on 5825 Web services. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Hybrid Imperialist Competitive-Gravitational Attraction Search Algorithm to Optimize Cloud Service Composition.pdf">A Hybrid Imperialist Competitive-Gravitational Attraction Search Algorithm to Optimize Cloud Service Composition</a><br/>
                    Suppose that the required Complex Service will be completed by a composition of n different simple services from 5825 prepared simple services, which were provided by ZibinZheng et al. in their produced dataset WSDream-QoSDataset2, according to Real-world QoS evaluation results [9, 10].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Method of QoS Deviation Monitoring for Web Services.pdf">A Method of QoS Deviation Monitoring for Web Services</a><br/>
                    Experiments were run in a Lenovo PC machine, configured as Intel Core i5-4200M 2.50 GHz CPU, RAM 4 GB. We choosed Matlab as our development environment and used the real data provided in QoS data sets [16-17] as the experimental QoS data.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Partial Selection Methodology for Efficient QoS-Aware Service Composition.pdf">A Partial Selection Methodology for Efficient QoS-Aware Service Composition</a><br/>
                    We adopt the WSDream dataset which records the values of QoS attributes of response time and throughput of 5,825 real-world web services from 73 countries [35], [36].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/BNQM A Bayesian Network based QoS Model for Grid service composition.pdf">BNQM: A Bayesian Network based QoS Model for Grid service composition</a><br/>
                    The first one is collected by Zheng, Zhang, and Lyu (2010) and Zhang, Zheng, and Lyu (2011) which contains 1,974,675 Web service response time and throughput records. Because this dataset contains the records of only two QoS attributes, it can not be used by structure learning algorithm to find the dependencies among different QoS attributes.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/HA-SLA A Hierarchical Autonomic SLA Model for SLA Monitoring in Cloud Computing.pdf">HA-SLA: A Hierarchical Autonomic SLA Model for SLA Monitoring in Cloud Computing</a><br/>
                    A service throughput and response time attributes are collected from existing dataset in [14] which it is also used in [15,16].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Multi-QoS Effective Prediction in Web Service Selection.pdf">Multi-QoS Effective Prediction in Web Service Selection</a><br/>
                    In this section, we conduct several experiments to show the prediction quality of our proposed approach on real-world Web service dataset[9].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/On the Best Adaptive Model for Web Services Response Time Prediction.pdf">On the Best Adaptive Model for Web Services Response Time Prediction</a><br/>
                    We have tested these models on a three columns dataset extracted from the Web service QoS dataset built by [5, 6] They collected a 339 * 5825 user-item matrix (rtmatrix) for response-time, where an entry Ra,i in the matrix is the response time of Web service i observed by the service user a.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Optimization of Location Allocation of Web Services Using A Modified Non-dominated Sorting Genetic Algorithm.pdf">Optimization of Location Allocation of Web Services Using A Modified Non-dominated Sorting Genetic Algorithm</a><br/>
                    To evaluate the effectiveness and efficiency of our proposed NSGA-II based approach to service location-allocation. We compare our approach with the GA-based single objective approach in Section 5 using an existing dataset, WS-DREAM [31] [32], which is a historical dataset on QoS of Web services from different locations. It contains the data of latencies from 339 different user locations invoked 5824 web services scattered over different locations. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Preference and Honesty Aware Trust Model for Web Services.pdf">Preference and Honesty Aware Trust Model for Web Services</a><br/>
                    However, the datasets have been used in IEEE conference papers [35]–[38], and available at http://www.zibinzheng.com/, which implies that they should be acceptable by other researchers.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/SLA-Driven State Monitoring for Cloud Services.pdf">SLA-Driven State Monitoring for Cloud Services</a><br/>
                    We use a Web Service dataset named WS-DREAM [12][18] as our experimental dataset. The dataset comprises response time values of 5825 web services from 339 users. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Web服务组合评分分配方法.pdf">Web服务组合评分分配方法</a><br/>
                    以Web服务QoS数据集[17-18]中提供的真实数据作为实验中QoS数据。<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/一种考虑QoS数据不确定性的服务选取方法.pdf">一种考虑QoS数据不确定性的服务选取方法</a><br/>
                    为了验证基于QoS数据不确定性服务选取方法的有效性和可靠性，原型系统采用WS-DREAM提供的数据集[20-21]，包括来自全球24个国家的339个用户对5825个Web服务的QoS评估反馈，其中包括响应时间和吞吐量两个QoS属性真是数据。<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Collaborative Approach to Predicting Service Price for QoS-Aware Service Selection.pdf">A Collaborative Approach to Predicting Service Price for QoS-Aware Service Selection</a><br/>
                    We use a real-world time-aware QoS dataset 1 [17]. It includes response time and throughput evaluation results from 142 requesters for 4,532 Web service providers on 64 different timestamps. To obtain the usage experience records, shown in Table I, we additionally generate data that contain tasks, priceperformance indexes, and prices of service providers.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Bayesian Model-based Prediction of Service Level Agreement Violations for Cloud Services.pdf">Bayesian Model-based Prediction of Service Level Agreement Violations for Cloud Services</a><br/>
                    In this paper, the datasets, or we say traces, come from WS-DREAM (Web Service QoS Datasets) 1.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Cloud computing service composition A systematic literature review.pdf">Cloud computing service composition: A systematic literature review</a><br/>
                    Unfortunately, the number of datasets that are available to all and in the research domain is very low and is limited to three datasets, QWS (Al-Masri & Mahmoud, 2009), WS-DREAM (Zibin, Yilei, & Lyu, 2010) and tpds 2012 (Zibin et al., 2013), and an unknown randomly generated dataset RG (Shangguang et al., 2011). Researchers have also used a synthetic generator, rarely. The datasets used in each study are listed in Table 2.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Personalized Services Recommendation based on Context-Aware QoS Prediction.pdf">Personalized Services Recommendation based on Context-Aware QoS Prediction</a><br/>
                    We have conducted our experiments on the dataset collected by Zibin Zheng et al. [24], which contains 1,542,884 web services invocation records executed by 100 distributed service consumers on 150 web services. The record of each invocation contains 6 parameters: IP, WS ID, RTT (round-trip time), Data Size, Response HTTP Code, and Response HTTP Message.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Two-Phase Online Prediction Approach for Accurate and Timely Adaptation Decision.pdf">A Two-Phase Online Prediction Approach for Accurate and Timely Adaptation Decision</a><br/>
                    In our experiments, 100 virtual services are created based on the realistic QoS datasets provided by [16], which record the non-functional performances (such as response time, throughput, etc.) of a large number of real-world service invocations. [16] Z. Zheng, Y. Zhang, and M. Lyu, “Distributed qos evaluation for real world web services,” in 8th International Conference on Web Services  (ICWS’10), july 2010, pp. 83 –90.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Evaluating Web Service QoS A Neural Fuzzy Approach.pdf">Evaluating Web Service QoS: A Neural Fuzzy Approach</a><br/>
                    However, the collected measurements are observed by only 1 service user which do not reflect different observation by various users. Zheng et al. [8] released a much larger dataset in comparison to [7] in which 5825 web services observed from 339 different distributed service users. However, the dataset do not support much variety of quality parameters (i.e. availability is not considered). <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Selecting Web Service for Multi-user Based on Multi-QoS Prediction.pdf">Selecting Web Service for Multi-user Based on Multi-QoS Prediction</a><br/>
                    To study the prediction performance on multi-QoS, we conduct several experiments to show the prediction quality of our proposed approach on real-world Web service dataset [19]. This dataset includes QoS performance of 5,825 openly-accessible real-world Web services from 73 countries. The QoS values are observed by 339 distributed computers located in 30 countries from PlanetLab4. The detail can be describe as Table.I.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Imperialist competitive algorithm with PROCLUS classifier for service time optimization in cloud computing service composition.pdf">Imperialist competitive algorithm with PROCLUS classifier for service time optimization in cloud computing service composition</a><br/>
                    Due to the importance of using a reliable dataset to evaluate the proposed algorithm, WSDream-QoSDataset2 (Zibin, Yilei, & Lyu, 2010) was used because it is a large dataset in which real-world service times were collected from 339 servers for 5,825 web services.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Dependability Assessment of Web Service Orchestrations.pdf">Dependability Assessment of Web Service Orchestrations</a><br/>
                    In the evaluation,we base the model parameters that characterize the response probability on real values, which are taken from literature[31], [35] whenever possible. In some cases (e.g., requestFlightChoice and makePayments) we used real values taken from the experiments performed in [35]. Otherwise,we based these parameters on the statistics presented in [31], which were related to generic WSs, thus characterizing all the other WSs with the same value of .<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A New Dataset and Benchmark for Cloud Computing Service Composition.pdf">A New Dataset and Benchmark for Cloud Computing Service Composition</a><br/>
                    In the following, there are two subtitles. First subtitle, A, will describe how the WSDREAD is used to extract a missingless dataset and the second one, B, will discuss about the way the CCSC_Benchmark is generated based onextracted dataset.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/An Enhanced Genetic Algorithm for Web Service Location-Allocation.pdf">An Enhanced Genetic Algorithm for Web Service Location-Allocation</a><br/>
                    To investigate the efficiency and effectiveness of our approach, we have conducted a full experimental evaluation to compare our proposed MFGA algorithm with a traditional GA-based approach, using an existing test dataset, WS-DREAM dataset [18].<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Time-Aware QoS Prediction Approach to Web Service Recommendation.pdf">A Time-Aware QoS Prediction Approach to Web Service Recommendation</a><br/>
                    We collect the data from PlanetLab [9, 10], which is a distributed test bed consisting of hundreds of computers all over the world.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/INVESTIGATING THE EFFECT OF HIDDEN LAYERS NUMBER ON WEB SERVICES RESPONSE TIME PREDICTION.pdf">INVESTIGATING THE EFFECT OF HIDDEN LAYERS NUMBER ON WEB SERVICES RESPONSE TIME PREDICTION</a><br/>
                    This research work continues our investigation presented in [1]. We have shown that the best adaptive model for web services response time prediction, on the rtmatrix built by [3, 4], is MLP.We also have underlined that the highest prediction accuracy, in terms of MSE, was achieved implementing DeltaBarDelta learning rule. In this study I have trained the MLP using DeltaBarDelta learning rule but in each case a different number of hidden layers on the entire 339 * 5825 rtmatrix that covers almost all web services in the world.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Efficient Service Selection in Mobile Information Systems.pdf">Efficient Service Selection in Mobile Information Systems</a><br/>
                    The first we chose is a real-world web service QoS dataset from [17–19] named WSDream.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/End-to-End QoS Mapping and Aggregation for Selecting Cloud Services.pdf">End-to-End QoS Mapping and Aggregation for Selecting Cloud Services</a><br/>
                    The second dataset was collected by Zheng et al. [25] which is part of their WS-DREAM project.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Web Service Evaluation Method Based on Time-aware Collaborative Filtering.pdf">Web Service Evaluation Method Based on Time-aware Collaborative Filtering</a><br/>
                    The experimental dataset WSDREAM records the invoking values of the realworld web service performance. WSDREAM contains 4 plain-text files, which are the users’ information, the services information, the response-time values of the service invoking and the throughput values of the service invoking. For simplicity, we only use the response-time as the reliable values to predict.<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/一种基于局部链接预测的Web服务质量稀疏性方法研究.pdf">一种基于局部链接预测的Web服务质量稀疏性方法研究</a><br/>
                    本章通过实验对提出的算法进行了验证。实验采用的平台为普通的个人ＰＣ，采用的数据集为公开的数据集。该数据集包含339个用户和5825个Web服务，数据集的详细信息见文献［８］。<br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A topic modeling approach for web service annotation.pdf">A topic modeling approach for web service annotation</a><br/>
                    In section 2 we describe a prototype based on our proposal, which uses this on- line LDA algorithm for categorizing and annotating the documentation of a corpus comprising 200 real service descriptors from the research dataset collected by Zhang et al. [19] available at http://www.wsdream.net/dataset.html <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Redundancy-Based Reliability Enhancement for Composite Services.pdf">Redundancy-Based Reliability Enhancement for Composite Services</a><br/>
                    The available web service dataset was generated by the combination of the real da- taset WS-DREAM (Zheng, Zhang et al. 2010) and the simulation, with a total of 2,000 web services as the initial candidates. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A COMPARATIVE STUDY FOR WEB SERVICES RESPONSE TIME PREDICTION.pdf">A COMPARATIVE STUDY FOR WEB SERVICES RESPONSE TIME PREDICTION</a><br/>
                    To train the three RNNs, we made use of the Web service QoS dataset built by (Yilei Zhang, et. al., 2011) They collected a 339 * 5825 user-item matrix for response-time, where an entry Ra,i in the matrix is the response time of Web service i observed by the service user a. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Input Projection Algorithms Influence in Prediction and Optimization of QoS Accuracy.pdf">Input Projection Algorithms Influence in Prediction and Optimization of QoS Accuracy</a><br/>
                    In this study, in order to train the MLP, we made use of two large datasets: RTMATRIX and FPMATRIX. Each matrix has a size of 339 lines x 5825 columns. RTMATRIX consists of web services response time values while FPMATRIX stores similar web services throughput values. In our previous research works [1]- [5] we concluded that MLP-2-M and MLP-2-CG offered the most accurate prediction results for RTMATRIX and FPMATRIX, respectively. FPMATRIX and RTMATRIX were built by Z. Zheng, Y. Zhang and M.R. Lyu in [20] and [21]. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Bottom-Up Fault Management in Service-Based Systems.pdf">Bottom-Up Fault Management in Service-Based Systems</a><br/>
                    In this regard, we used the WS- Dream QoS-Dataset [Zheng and Lyu 2010]. This data-set contains 150 Web services distributed in computer nodes located in 22 different countries, where each Web ser- vice is invoked 100 times by a service user. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Class of Tractable Models for Run-Time Performance Evaluation.pdf">A Class of Tractable Models for Run-Time Performance Evaluation</a><br/>
                    To this end, we consider the wsdream dataset recently presented in [28]. This dataset consists of a collection of 15000 response time traces span- ning 150 invocation sequences for a set of 100 public web services. Each web service is called several times using dif- ferent clients deployed on the PlanetLab infrastructure. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Cost Efficient Scheduling Strategy to Guarantee Probabilistic Workflow Deadlines.pdf">A Cost Efficient Scheduling Strategy  to Guarantee Probabilistic Workflow Deadlines</a><br/>
                    Our evaluations are based on 30287600 response time measurements taken by 142 users querying 4532 real web- services [13]. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Three-Step Service Experience Approach with Feedback for Service Provider.pdf">A Three-Step Service Experience Approach with Feedback for Service Provider</a><br/>
                    In order to verify the service experience approach, we use the data of WS-DREAM website [11, 12]. There are 100 Web services which are monitored by using 150 distributed computer nodes located all over the world. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Automated conflict resolution in collaborative data sharing systems using community feedbacks.pdf">Automated conflict resolution in collaborative data sharing systems using community feedbacks</a><br/>
                    We used the WSDream QoS-Dataset [52] to model the different service quality behaviors. This data-set contains around 150 Web services distributed in computer nodes located all over the world (i.e., distributed in 22 different countries), where each Web service is invoked 100 times by a service user. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Automated Self-healing Framework for Service-Oriented Systems.pdf">Automated Self-healing Framework for Service-Oriented Systems</a><br/>
                    Our prototype is deployed to study the performance of different fault management strategies. The WSDream-QoSDataset [22] is used, which contains 150 Web services distributed in computer nodes located all over the world, where  each Web service is invoked 100 times by a service user. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Construction and Application of Learning Petri Net.pdf">Construction and Application of Learning Petri Net</a><br/>
                    A Web service performance dataset is employed for simulation. This dataset includes 100 publicly available Web services located in more than 20 countries. 150 service users executed about 100 invocations on each Web service. Each service user recorded execution time and invocation failures in dataset [27]. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Empower service directories with knowledge.pdf">Empower service directories with knowledge</a><br/>
                    The service descriptions are selected from the WS-DREAM dataset [4]. Ten queries are submitted to the service directory, and the response times of the service directory are calculated. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Integrating Fault-Tolerance Method into Service-Oriented Computing.pdf">Integrating Fault-Tolerance Method into Service-Oriented Computing</a><br/>
                    The WSDream-QoSDataset [26] is used, which contains 150 Web services distributed in computer nodes located all over the world (i.e., distributed in 22 different countries), where each Web service is invoked 100 times by a service user. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Modeling dynamic recovery strategy for composite web services execution.pdf">Modeling dynamic recovery strategy for composite web services execution</a><br/>
                    We took real QoS values from WS-DREAM [28]. All used artifacts are available2. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Optimal Service Selection Based on Business for Cloud Computing.pdf">Optimal Service Selection Based on Business for Cloud Computing</a><br/>
                    The testbed contains a real-world web service QoS dataset WS-DREAM described in [13], which is supported by about 1.5 millions web service records of 150 customers in 24 countries. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Prediction of Service Reliability Based on Grouping.pdf">Prediction of Service Reliability Based on Grouping</a><br/>
                    To demonstrate the effectiveness of our proposed RPMBG in comparison with the other prediction methods, we choose a real-world Web service performance dataset[1] for experiments. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Reliability Prediction for Service-Oriented System via Matrix Factorization in a Collaborative Way.pdf">Reliability Prediction for Service-Oriented System via Matrix Factorization in a Collaborative Way</a><br/>
                    Our experiments are conducted on a real-world dataset containing 15000 response records collected by Zheng et al. [20]. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Reliable Service Composition via Automatic QoS Prediction.pdf">Reliable Service Composition via Automatic QoS Prediction</a><br/>
                    Real-world Web service performance dataset (published at www.wsdream.net) [12] is comprised of failure probabilities of 100 Web services observed by all the 150 service users. This data is presented as a 150 × 100 failure probability matrix, which we refer to as RP (i.e., Reliability Performance). <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Self-healing Framework for Cloud-based Services.pdf">Self-healing Framework for Cloud-based Services</a><br/>
                    Our prototype is deployed to study the performance of different fault management strategies. The WSDream- QoSDataset [31] is used, which contains 150 services distributed in computer nodes located all over the world, where each Cloud service is invoked 100 times by a service user. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Session Reliability of Web Systems under Heavy-Tailed Workloads An Approach Based on Design and Analysis of Experiments.pdf">Session Reliability of Web Systems under Heavy-Tailed Workloads An Approach Based on Design and Analysis of Experiments</a><br/>
                    Part of the validation of predictions made by our model is based on the empirical data for web services reliability used recently in [57], [58], and made publicly available at [54]. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/Toward Next Generation Web Service Technology Overly Network A Quantitative Approach.pdf">Toward Next Generation Web Service Technology Overly Network A Quantitative Approach</a><br/>
                    For this reason some web services datasets such as OWLS-TC 4.0 [19] and WS- DREAM [20] are used. These two test cases contain real word web services descriptions selected from real service directories and contain a total of 4821 web service descriptions. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/User feature-aware trustworthiness measurement of cloud services via evidence synthesis for potential users.pdf">User feature-aware trustworthiness measurement of cloud services via evidence synthesis for potential users</a><br/>
                    We used the WS-DREAM datasets [8,29], which collected the real-world QoS data from Planet-Lab. Considering the deficiency of user feature information, we extended WS-DREAM and supplemented some real data about user feature by using QueryIP services [30] and Hurricane Electric Internet services [31]. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/User Features-aware Trust Measurement of Cloud Services via Evidence Synthesis for Potential Users.pdf">User Features-aware Trust Measurement of Cloud Services via Evidence Synthesis for Potential Users</a><br/>
                    We used the WS-DREAM datasets [28], which collected the real-world QoS evaluation results from Planet-Lab. Considering the deficiency of user feature information, we extended WS-DREAM and supplemented some real data about user feature by using QueryIP services [29] and Hurricane Electric Internet services [30]. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/A Ranking-oriented Hybrid Approach to QoS-aware Web Service Recommendation.pdf">A Ranking-oriented Hybrid Approach to QoS-aware Web Service Recommendation</a><br/>
                    In this paper, we used a public data set of real-world Web services introduced in [25], which contains over one and a half millions QoS records from 339 users and 5,825 Web services distributed all over the world. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/CoMFS A Collaborative Matrix Factorization System for Quality-of-Service Prediction.pdf">CoMFS A Collaborative Matrix Factorization System for Quality-of-Service Prediction</a><br/>
                    We have conducted our experiments on a public real world Web service QoS dataset, which is collected by Zibin Zheng et.al. It contains 1,974,675 Web service response time (0-20s), collected from 339 distributed service users on 5,825 Web services worldwide. <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/QoS Prediction for Web Services via L2,1-Norm Regularized Matrix Completion Approach.pdf">QoS Prediction for Web Services via L2,1-Norm Regularized Matrix Completion Approach</a><br/>
                    We have conducted some experiments using a real public web services QoS dataset, which is collected by Zibin Zheng et.al.(http://www.wsdream.net). <br/>
                    <br/>
                    </div>
                </li>
                <li>
                    <div><a href="./papers/How does Neighborhood Matter An Empirical Study on MF based QoS Prediction Framework.pdf">How does Neighborhood Matter? An Empirical Study on MF based QoS Prediction Framework</a><br/>
                    We have conducted our experiments on a public real world Web service QoS dataset, which is collected by Zibin Zheng et.al [1]. <br/>
                    <br/>
                    </div>
                </li>
            </ol>
        </div>
    </div>
</body>